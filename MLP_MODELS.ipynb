{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPu+qqImXbtTi/mxYcq/2ST"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importamos las librerías requeridas"],"metadata":{"id":"kWNR-Fwcj3cc"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from matplotlib import pyplot as plt"],"metadata":{"id":"EllIh9-Ej860"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Seleccionamos el modelo de datos"],"metadata":{"id":"ImdgnAUXj_ty"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQ_YKIG9ehWj"},"outputs":[],"source":["\"\"\" Por cuestiones de comodidad a la hora de cargar los modelos de datos, se ha creado un repositorio en GitHub para cargarlos remotamente \"\"\"\n","# Escogemos el modelo de datos con los que deseamos operar (disponibles 7 modelos)\n","model = 'Modelo4/'\n","url = 'https://raw.githubusercontent.com/100386357/RNA/main/models/' + model\n","train_set_IN = pd.read_csv(url + 'Training/Training_IN.csv', header='infer', delimiter=',')\n","train_set_OUT = pd.read_csv(url + 'Training/Training_OUT.csv', header='infer', delimiter=',')\n","valid_set_IN = pd.read_csv(url + 'Validation/Validation_IN.csv', header='infer', delimiter=',')\n","valid_set_OUT = pd.read_csv(url + 'Validation/Validation_OUT.csv', header='infer', delimiter=',')\n","test_set_IN = pd.read_csv(url + 'Testing/Testing_IN.csv', header='infer', delimiter=',')\n","test_set_OUT = pd.read_csv(url + 'Testing/Testing_OUT.csv', header='infer', delimiter=',')\n","\n","# SELECCION DE LA SALIDA. Num de columna del target\n","X_train = np.array(train_set_IN)\n","y_train = np.array(train_set_OUT)\n","X_valid = np.array(valid_set_IN)\n","y_valid = np.array(valid_set_OUT)\n","X_test = np.array(test_set_IN)\n","y_test = np.array(test_set_OUT)\n","num_train_samples=len(y_train)"]},{"cell_type":"markdown","source":["# Definimos las funciones que construyen los modelos en base a las arquitecturas requeridas para las pruebas"],"metadata":{"id":"yyJ-lT_skTAv"}},{"cell_type":"code","source":["# Definir forma de la entrada de la red\n","input_shape = (X_train.shape[1],) # Utilizamos los datos de entrenamiento para definir la tupla , en este caso sera (21,)\n","\n","def create_PM1_sigmoid(num_hidden_neurons = 50):\n","  # 1 capa oculta y 1 neurona de salida con sigmoide\n","  model = Sequential() \n","  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='sigmoid'))\n","  model.add(Dense(1,activation='sigmoid'))\n","  return model\n","\n","def create_PM2_sigmoid(num_hidden_neurons = 50):\n","  # 2 capas oculta y 1 neurona de salida con sigmoide\n","  model = Sequential() \n","  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='sigmoid'))\n","  model.add(Dense(num_hidden_neurons, activation='sigmoid'))\n","  model.add(Dense(1,activation='sigmoid')) \n","  return model\n","\n","def create_PM3_sigmoid(num_hidden_neurons = 50):\n","  # 3 capa ocultas y 1 neurona de salida con sigmoide\n","  model = Sequential()\n","  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='sigmoid'))\n","  model.add(Dense(num_hidden_neurons, activation='sigmoid'))\n","  model.add(Dense(num_hidden_neurons, activation='sigmoid'))\n","  model.add(Dense(1,activation='sigmoid')) \n","  return model\n","\n","def create_PM1_relu(num_hidden_neurons = 50):\n","# 1 capa oculta con relu y 1 neurona de salida con sigmoide\n","  model = Sequential()\n","  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='relu'))\n","  model.add(Dense(1,activation='sigmoid'))\n","  return model\n","\n","def create_PM2_relu(num_hidden_neurons = 50):\n","# 2 capa ocultas con relu y 1 neurona de salida con sigmoide\n","  model = Sequential()\n","  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='relu'))\n","  model.add(Dense(num_hidden_neurons, activation='relu'))\n","  model.add(Dense(1,activation='sigmoid'))\n","  return model\n","\n","def create_PM3_relu(num_hidden_neurons = 50):\n","# 3 capas ocultas con relu y 1 neurona de salida con sigmoide\n","  model = Sequential()\n","  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='relu'))\n","  model.add(Dense(num_hidden_neurons, activation='relu'))\n","  model.add(Dense(num_hidden_neurons, activation='relu'))\n","  model.add(Dense(1,activation='sigmoid'))\n","  return model\n","\n","# Modelo lineal, solo para comparar con el programa desarrollado\n","def create_lineal():\n","  model = Sequential()\n","  model.add(Dense(1, input_shape=input_shape, activation='linear'))\n","  return model\n","\n","\"\"\" AGRUPACIÓN DE LAS DISTINTAS ARQUITECTURAS (MODELOS) A EVALUAR \"\"\"\n","models = {\n","    # 1 capa oculta con una neurona (ReLU) y  1 salida (sigmoide)\n","    \"m1r\": create_PM1_relu(1),\n","\n","    # 1 capa oculta con 5 neuronas (ReLU) y  1 salida (sigmoide)\n","    \"m2r\": create_PM1_relu(5),\n","\n","    # 1 capa oculta con 15 neuronas (ReLU) y  1 salida (sigmoide)\n","    \"m3r\": create_PM1_relu(15),\n","\n","    # 1 capa oculta con 20 neuronas (ReLU) y  1 salida (sigmoide)\n","    \"m4r\": create_PM1_relu(20),\n","\n","    # 2 capas ocultas con 20 neuronas (ReLU) y  1 salida (sigmoide)\n","    \"m5r\": create_PM2_relu(20),\n","\n","    # 3 capas ocultas con 20 neuronas (ReLU) y 1 salida (sigmoide)\n","    \"m6r\": create_PM3_relu(20),\n","\n","    # 1 capa oculta con una neurona (sigmoide) y  1 salida (sigmoide)\n","    \"m1s\": create_PM1_sigmoid(1),\n","\n","    # 1 capa oculta con 5 neuronas (sigmoide) y  1 salida (sigmoide)\n","    \"m2s\": create_PM1_sigmoid(5),\n","\n","    # 1 capa oculta con 15 neuronas (sigmoide) y  1 salida (sigmoide)\n","    \"m3s\": create_PM1_sigmoid(15),\n","\n","    # 1 capa oculta con 20 neuronas (sigmoide) y  1 salida (sigmoide)\n","    \"m4s\": create_PM1_sigmoid(20),\n","\n","    # 2 capas ocultas con 20 neuronas (sigmoide) y  1 salida (sigmoide)\n","    \"m5s\": create_PM2_sigmoid(20),\n","\n","    # 3 capas ocultas con 20 neuronas (sigmoide) y 1 salida (sigmoide)\n","    \"m6s\": create_PM3_sigmoid(20)\n","}"],"metadata":{"id":"RWLxmBookV01"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Seleccionamos el modelo que deseamos probar"],"metadata":{"id":"qRV_g_PlkknY"}},{"cell_type":"code","source":["# Seleccionamos la clave asociada al modelo que deseamos cargar\n","model_id = \"m6r\"\n","model = models[model_id]\n","\n","# Imprimimos la visualización del modelo\n","model.summary()"],"metadata":{"id":"q0y4vzOaknR5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Compilamos el modelo y mostramos la evolución del MSE"],"metadata":{"id":"ng38aRtyk7ud"}},{"cell_type":"code","source":["# CONFIGURAR MODELO Y ENTRENAMIENTO\n","lr = 0.3 # Factor de aprendizaje\n","epochs = 100 # Número de ciclos de aprendizaje\n","batch_size = 32 # Tamaño del lote\n","\n","# Proceso de compilación del modelo\n","model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0), metrics=['mse'] )\n","historico = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(X_valid,y_valid),\n","shuffle=False, validation_freq=1)\n","\n","# Muestra por pantalla una gráfica con la evolución del MSE de entrenamiento y validación\n","plt.plot(historico.history['loss'])\n","plt.plot(historico.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper right')\n","plt.show()"],"metadata":{"id":"Nc5IoYTplH_G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluamos el modelo con el conjunto de test"],"metadata":{"id":"EEV2fHslmO4v"}},{"cell_type":"code","source":["# Evaluar el modelo con el fichero de test\n","results_test = model.evaluate(X_test, y_test)\n","results_test[0]"],"metadata":{"id":"3FCGyf1nmSYy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Guardamos en un fichero .txt la predicción (desnormalizada)"],"metadata":{"id":"i2AVZSaJmaJP"}},{"cell_type":"code","source":["# Predicciones en test\n","test_pred = model.predict(X_test)\n","\n","# Crear un np-array: columna 1 predicciones, columna 2 target\n","comp = np.append(test_pred, y_test, axis = 1)\n","comp_df = pd.DataFrame(comp, columns=['prediccion','target'])\n","\n","# Desnormalizamos las salidas de la red neuronal y las salidas deseadas\n","max_value = 99 # Valor máximo (sin normalizar) de la salida \"usr\"\n","min_value = 0 # Valor mínimo (sin normalizar) de la salida \"usr\"\n","comp_df = comp_df * (max_value - min_value) + min_value\n","\n","# Escribimos en un fichero .txt la comparativa de ambas salidas\n","np.savetxt('MLP_output_comparison.txt', comp_df, fmt='%f')"],"metadata":{"id":"umBPKu0KmtEG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Guardamos en ficheros .txt la evolución de los MSE de entrenamiento y validación"],"metadata":{"id":"4B7K0cEoubyt"}},{"cell_type":"code","source":["# Escribe en un fichero .txt la evolución MSE de entrenamiento y validación\n","# Los valores están redondeados a 3 cifras significativas decimales\n","# Por comodidad visual, se ha eliminado el formato de notación científica\n","np.savetxt('historicoTrainLoss.txt', historico.history['loss'], fmt='%f')\n","np.savetxt('historicoValLoss.txt', historico.history['val_loss'], fmt='%f')"],"metadata":{"id":"LTZCjIVnuiQM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Guardamos el modelo resultante del entrenamiento"],"metadata":{"id":"RcGmF5cVwU4k"}},{"cell_type":"code","source":["# Guarda el modelo completo\n","model.save('modelo.h5')"],"metadata":{"id":"D5CQldOnwX6y"},"execution_count":null,"outputs":[]}]}